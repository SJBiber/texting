
## 글 쓴 이유

- 금일 배운 Text Mining 을 어떻게 사용하고 어떨때 사용하는지에 대한 학습 내용을 토대로 정리하고자 작성함

## 텍스트 마이닝은 왜하는가 ?

- 뉴스 댓글 , 포털의 카페 , 블로그 , 소셜 미디어 등을 통해 자신의 경험과 의견을 자유롭게 공유하고있음
- 자연어는 컴퓨터가 이해할 수 있도록 수치형 데이터로 변환해야함
	- 예를 들어 블로그 크롤링 , 리뷰 데이터 같은 Text 형식의 데이터
	- 초기의 하향식 규칙 기반 접근 방식은 수많은 규칙과 예외를 만들어야 했음
	- 대규모 데이터 기반 접근 방식이 도입된 이후 정확성이 크게 향상됨
- 텍스트 마이닝은 자연어를 분석 가능한 형태로 변환 , 데이터에 포함된 사람들의 공통적인 생각과 의견을 읽어 인사이트를 도출


## 텍스트 마이닝이 어려운 이유

- 텍스트 데이터를 수집하기 어려움
	- 웹 크롤링을 배우거나 전문 업체로부터 구매해야함
- 텍스트 데이터를 분석하기 좋게 전처리하기가 어려움
	- 형태소 부누석기를 활용해 형태소 단위로 나누는 과정이 필요
- 텍스트 전처리 작업이 너무 많음
	- 불용어 제거(불용어 : 너무 자주쓰이는 단어 (을 는 이 가)) , 정규 표현식 처리 등이 필수인데 정규 표현식은 복잡하고 난해함
- 텍스트 데이터로 어떤 분석을 해야 할지 막막함
	- 고빈도 단어 시각화 , 연관 단어 분석 , 네트워크 분석 및 토픽 모델링 등을 실행

## 텍스트 전처리 과정

1. 텍스트 정제 : 수집한 텍스트 데이터셋에는 오탈자와 불필요한 문자가 많음 , 말뭉치에서 한글 띄어쓰기를 교정하고 , 특수문자 / 기호 / 이모지 / 불용어 등을 제거
2. 토큰화 : 분석 목적에 따라 토큰(문장 , 단어 또는 글자 등)으로 나눔
3. 정규화 : 단어에서 어간을 남기는 어간 추출을 수행 (먹었다 -> 먹 + 었 + 다)
	- 해당 문맥을 고려해서 단어를 원형을 변환하는 표제어 추출을 수행 (먹었다 -> 먹다)
4. 품사 부착 : 단어를 문접적인 기능에 따라 분류하는 품사를 부착 (먹/vv + 었/EP + 다/EF)
	- 같은 단어여도 문맥에 따라 품사가 다를 수 있다 (오늘/MAG + 은/JX , 오늘/NNG + 날씨/NNG)
5. BoW 생성 : 각 문서로 형태소 분석을 실행하고 일부 품사만 남긴 리스트를 모은 Bag of Words를 생성
	- Bag of Words는 문서 집합에서 출현한 단어를 한 봉투에 쏟아부어 단어의 순서를 고려하지않음
6. DTM 생성 : Bag of Words를 분석 가능한 형태인 Document-Term Matrix로 변환함
	- 문서-단어 행렬은 행과 열은 문서와 단어이고 , 각 성분은 해당 문서에서 단어가 출현한 횟수다.

### 불필요한 문자 / 기호 제거 및 앞바벳 통일

1. 먼저 리뷰 데이터가 담긴 xlxs 파일을 읽음

df = pd.read_excel('Galaxy_Book_Review_20250131.xlsx') 
df.head()

|date|star|like|text|
|---|---|---|---|
|2025-01-13|5|3|빠르게 배송해주셔서 감사합니다.여기서 항상 사무용 노트북 주문하고 있네요.한가지 아...|
|2025-01-25|5|2|지난번에 구입하고 일주일 간격으로 재구매.좋아요. 사장님 사은품 없습니꽈? 사이즈...|
|2025-01-14|5|2|메모리 잘 추가되어 도착했고, 윈도우 설치할때 ms 계정때문에 잠깐 어려웠는데 인터...|
|2025-01-23|4|2|자격증 프로그램도 잘 돌아가고 생각보다 큰 걸 샀지만 만족해요. 배터리는 좀 빨리 ...|
|2025-01-25|5|2|가격도 맘에들고 다 좋아요!! 엄마가 쓰려고 구매했는데 만족하셔요|


2. 정규표현식 패턴을 설정하여 한글 완성형 , 알파벳 대소문자 , 숫자를 제외한 패턴을 먼설정
pt = '[^가-힣A-Za-z0-9]''

3. 해당 정규 표션식 패턴을 한 칸 공백으로 변경한 후 모든 알파벳을 대문자로 변경
df['text'] = df['text'].str.replace(pat=pt ,repl = ' ', regex = True)
df['text'] = df['text'].str.upper()
df.head()

| date       | star | like | text                                              |
| ---------- | ---- | ---- | ------------------------------------------------- |
| 2025-01-13 | 5    | 3    | 빠르게 배송해주셔서 감사합니다 여기서 항상 사무용 노트북 주문하고 있네요 한가지 아... |
| 2025-01-25 | 5    | 2    | 지난번에 구입하고 일주일 간격으로 재구매 좋아요 사장님 사은품 없습니꽈 사이즈...    |
| 2025-01-14 | 5    | 2    | 메모리 잘 추가되어 도착했고 윈도우 설치할때 MS 계정때문에 잠깐 어려웠는데 인터...  |
| 2025-01-23 | 4    | 2    | 자격증 프로그램도 잘 돌아가고 생각보다 큰 걸 샀지만 만족해요 배터리는 좀 빨리 ...  |
| 2025-01-25 | 5    | 2    | 가격도 맘에들고 다 좋아요 엄마가 쓰려고 구매했는데 만족하셔요                |

## 한글 맞춤법 검사기 비교

| **구분**                                               | **상세 내용**                                                                          | **비용** | **속도** | **정확도** | **코딩 복잡도** |
| ---------------------------------------------------- | ---------------------------------------------------------------------------------- | ------ | ------ | ------- | ---------- |
| **맞춤법 검사기**                                          | - 네이버에서 제공하는 맞춤법 검사기입니다.<br><br>  <br><br>- 웹 크롤러를 직접 개발하여 사용합니다.                  | 무료     | 느림     | 가장 낮음   | 낮음         |
| **py-hanspell-aideer**                               | - 네이버 맞춤법 검사기를 파이썬으로 구현한 패키지입니다.                                                   | 무료     | 느림     | 가장 낮음   | 가장 낮음      |
| **HuggingFace Hub**<br><br>  <br><br>(Text2Text Gen) | - **et5-typos-corrector** 모델을 사용합니다.<br><br>  <br><br>(ETRI-et5 기반 한글 구어체 맞춤법 교정기) | 무료     | 느림     | 좋음      | 보통         |
| **HuggingFace Hub**<br><br>  <br><br>(Text2Text Gen) | - **kogrammar-base** 모델을 사용합니다.<br><br>  <br><br>(국립국어원 맞춤법 교정 말뭉치)                | 무료     | 매우 느림  | 낮음      | 보통         |
| **OpenAI API**<br><br>  <br><br>(gpt-4)              | - OpenAI에서 제공하는 `gpt-4o`, `gpt-4o mini` 등 다양한 모델을 사용합니다. (API Key 필요)              | 유료     | 보통     | 가장 좋음   | 보통         |

## 형태소 분석

- 형태소는 더 이상 분리할 수 없는 최소 의미 단위 , 텍스트를 형태소로 나누는 것을 형태소 분석이라고 함
	- ex : '가방'은 '가'와 '방'으로 나눌 수 없으므로 하나의 형태소로 간주
- 형태소 분석기는 내장 형태소 사전과 불용어 사전을 참조하여 형태소 분석을 수행
	- 이때 신조어나 복합명사는 사용자 사전에 추가하거나 수작업으로 정제하는 과정이 필요 (복리 , 후생 을 하나의 단어인 복리후생으로 내부적으로 사전을 따로 만들어 분리 시키지 못하게 막음)

### 형태소 분석 과정

1. kiwipiepy를 가져오기위해 Kiwi를 설치 및 임포트
#설치
pip install kiwipiepy
#임포트
from kiwipiepy import Kiwi

2. 형태소 분석기 객체를 생성함
#kiwi가 업데이트되면서 model_type에 'sbg' 대신 'cong'을 사용
kiwi = Kiwi(model_type = 'cong' ,typos = 'basic_with_continual_and_lengthening')

3. corrected = '복리후생으로워라밸부터챙기자'이라는 텍스트를 형태소 분석을 실행하여 분리시킴
kiwi.tokenize(corrected)
\[ Token(form='복리', tag='NNG', start=0, len=2), 
Token(form='후생', tag='NNG', start=2, len=2), 
Token(form='으로', tag='JKB', start=4, len=2), 
Token(form='워라밸', tag='NNG', start=7, len=3), 
Token(form='부터', tag='JX', start=10, len=2), 
Token(form='챙기', tag='VV', start=13, len=2), 
Token(form='자', tag='EF', start=15, len=1), 
Token(form='.', tag='SF', start=16, len=1) ]

## 불용어 삭제 과정

1. 필요한 모듈 임포트
from kiwipiepy.utils import Stopwords

2. 내장 불용어 객체 생성 및 목록 확인
#객체생성 
stopwords = Stopwords()
#불용어목록확인 
stopwords.stopwords
{('ᆫ', 'ETM'), ('ᆫ', 'JX'), ('ᆫ다', 'EF'), ('ᆯ', 'ETM'), ('가', 'JKS'), ('같', 'VA'), ('것', 'NNB'),...

3. 형태소 분석을 실행하고 불용어 삭제한 결과를 확인
kiwi.tokenize(text = corrected , stopwords = stopwords )

\[Token(form='복리', tag='NNG', start=0, len=2),
 Token(form='후생', tag='NNG', start=2, len=2),
 Token(form='워라밸', tag='NNG', start=7, len=3),
 Token(form='챙기', tag='VV', start=13, len=2),
 Token(form='자', tag='EF', start=15, len=1)]

## 사용자 사전 추가하는 과정

1. 사용자 사전에 새로운 단어를 추가함
#키위사전에복리후생단어를명사로추가
kiwi.add_user_word(word = '복리후생', tag = 'NNG' , score = 1)

2. 사전에 넣어둔 대로 복리 / 후생이 복리후생으로 붙어서 처리가 됨
tokens = kiwi.tokenize(text = corrected , stopwords = stopwords )
tokens[0]

Token(form='복리후생', tag='NNG', start=0, len=4)

## 품사 선택 후 동사 및 명사를 토큰으로 출력하는 방법

1. 형태소 분석 결과에서 선택할 품사(용언과 체언) 목록을 리스트로 생성
#vv동사
-R(놀다 , 놀아) -> 변하지않음
-I(묻다 , 물어봐라) -> 사용방식에 따라서 단어 형태가 변함
tag_v=['VV','VV-R','VV-I','VA','VA-R','VA-I']

nng : 명사
nnp : 사람이름
tag_n=['NNG','NNP']

2. 품사가 용언과 체언인 형태소만 선택하고 , 품사가 용언일 때 종결어미 '다'를 결합
\[ token.form + '다' if token.tag in tag_v else token.form for token in tokens if token.tag in tag_v + tag_n ]

출력 결과
\['복리후생', '워라밸', '챙기다']

## BoW 생성 : 문서 집합으로 형태소 분석 실행

1. 문서 집합에서 각 문서를 형태소로 나누고 일부 품사를 남긴 morphs를 생성
morphs = []
for corrected in tqdm(df['corrected']):
	tokens = tokenizer(corrected)
	morphs.append(tokens)

2. 한글 맞춤법 검사를 실행한 문서와 형태소 분석 결과를 비교
for i in range(5):
	print(df['corrected'].iloc[i])
	print(morphs[i] ,end ='\n\n')

- 출력 결과
빠르게 배송해 주셔서 감사합니다 여기서 항상 사무용 노트북 주문하고 있네요 한 가지 아쉬운 점은 윈도우와 오피스 포함 저렴이 버전 노트북 있으면 좋겠어요 삼성도 이젠 OS 없는 식으로 나와서 아쉽네요.
\['빠르다', '배송', '감사', '사무', '노트북', '주문', '아쉽다', '점', '윈도우', '오피스', '포함', '버전', '노트북', '좋다', '삼성', '이제', '나오다', '아쉽다']

지난번에 구입하고 일주일 간격으로 재구매 좋아요 사장님 사은품 없습니까? 사이즈도 성능도 딱 좋습니다 봐서 한 대 더 살 수도 있습니다 사은 품 주세요.
\['지난번', '구입', '일주일', '간격', '구매', '좋다', '사장', '사은품', '사이즈', '성능', '좋다', '사다', '있다', '사은', '품', '주다']

메모리 잘 추가되어 도착했고 윈도우 설치할 때 MS 계정 때문에 잠깐 어려웠는데 인터넷에 너무 잘 나와 문제 없이 설치했습니다 찍어 놓은 사진은 후면 모델 확인 차 갖고 있는 거밖에 없네요 집에 가면 구매 확정 누른다는 걸 자꾸 잊음.
\['메모리', '추가', '도착', '윈도우', '설치', '계정', '어렵다', '인터넷', '나오다', '문제', '설치', '찍다', '사진', '후면', '모델', '확인', '갖다', '집', '가다', '구매', '확정', '누르다', '잊다']

자격증 프로그램도 잘 돌아가고 생각보다 큰 걸 샀지만 만족해요 배터리는 좀 빨리 닳는 것 같지만요.
\['자격증', '프로그램', '돌아가다', '생각', '크다', '사다', '만족', '배터리', '닳다']

가격도 맘에 들고 다 좋아요 엄마가 쓰려고 구매했는데 만족하셔요.
\['가격', '맘', '들다', '좋다', '엄마', '쓰다', '구매', '만족']

## n-gram

- n-gram은 텍스트에서 연속하는 n개의 단어를 하나의 단위로 묶은것
	- n의 크기에 따라 monogram , bigram , trigram 등으로 구분
- 도입 초기에는 통계적 언어 모델링에서 언어의 패턴과 확률을 추정하기 위해 사용
	- 어떤 단어들이 자주 함께 등장하는지 파악 가능
	- n-1개 단어만 고려하여 n번째 단어의 출현 확률을 추정할 수 있음

