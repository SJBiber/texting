 [[1. 통계]] 
## **글 쓴 이유**

 - 데이터 분석 공부를 할때 햇갈리거나 이해하지 못하는 통계 관련 단어가 있어 이해하며 정리하기 위해 작성

### **데이터 중심과 퍼짐 ( 기술 통계 관련 )**

#### **정리하기 앞서 추가 용어 정리**

 **- 모집단 : 우리가 알고싶은 대상 전체**

 **- 표본 : 모집단에서 실제로 뽑아서 조사한 일부분**

 **- 모수 : 모집단의 특성을 나타내는 진짜 값**

 **- 통계량 : 표본을 통해 계산해 낸 값** , 우리가 실제로 계산해서 모수를 추측하는데 사용

####  **1. 평균**

 - 모든 데이터 값을 더한 후 데이터의 개수로 나눈 값

 **- 데이터의 전체적인 무게 중심을 나타내지만 , 값이 너무 크거나 작은 이상치에 영향을 많이 받는다는 단점**이 있음

![](https://blog.kakaocdn.net/dna/bb3Mii/dJMcacV32cq/AAAAAAAAAAAAAAAAAAAAAIGzvXjjVXqT5IDq60pOSLZYEcyy8enBIncFKA4dOuZS/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=6MOBqWB6u96fJeCYlVm3PXEi2ys%3D)

 **(시그마 : 합계 , x : 개별 데이터 값 , n : 전체 데이터 개수)**

#### **2**. 모평균****

 - 모집단 전체 데이터의 평균

 - 이론적인 값, 우리가 데이터 분석을 통해 최종적으로 맞추고 싶어하는 실질적인 데이터 값

![](https://blog.kakaocdn.net/dna/kGjOB/dJMcafL1GMV/AAAAAAAAAAAAAAAAAAAAAL97mPuDGh_4tyUueYvzQf2zk2OzNusOxdXZ7NQyR60Y/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=L%2Fcqual7XBpDR4vA9oiXH9uCTn4%3D)

**(시그마 : 합계 , X : 모집단 데이터 값 , N : 모집단 전체 데이터 개수)**

#### **3. 최빈값**

 - **데이터 중에서 가장 자주 나타나는 값**

 - 평균이나 중앙값과 달리 숫자가 아닌 범주형 데이터에서도 사용할 수 있음

#### **4. 중앙값**

 - 데이터를 크기순으로 나열했을 때 가장 한가운데 있는 값

 **- 이상치가 포함된 데이터에서는 평균보다 데이터의 대표성을 더 잘 나타낼 때가 많음**

#### **5. 분산과 표준 편차 (⭐️)**

 - 데이터가 평균으로부터 얼마나 멀리 떨어져 있는지 , 퍼짐정도를 나타냄

 **- 분산 :** **편차(데이터값 - 평균)의 제곱의 합을 데이터 개수로 나눈 것**

      *** 데이터 셋의 편차들의 총합은 0이라 얼마나 퍼져있는지 알수 없음, - 부호를 없애기 위해 편차를 제곱해서 계산**

![](https://blog.kakaocdn.net/dna/ok517/dJMcag5fxTu/AAAAAAAAAAAAAAAAAAAAAFveq7TICGnzXtoOfp0hjAFRtmnApXKvpZm2Vj1Nyfpa/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=%2BbW54fB1H6noJLEKHVhKOzKNSpc%3D)

**(시그마 : 합계 , x : 개별 데이터 값 , n : 데이터 개수)**

 **** n-1을 해주는 이유**

  --> 간단히 말해서 **표본에서 구한 분산이 실제 모집단의 분산보다 작게 추정되는 편향을 보정하기 위해 뺌**

 **** n-1을 해주는 직관적인 이유**

  --> 우리는 표본 분산을 계산할 때 진짜 모집단의 평균을 모르기 때문에 표본의 평균을 사용함

  --> **데이터들은 실제 전체 평균(모평균)보다 자신들의 표본 평균에 더 가까이 몰려 있는 경향이 있음**

  --> **표본 평균을 기준으로 편차 제곱으로 계산하게 되면 , 실제 모집단 평균을 기준으로 계산했을 때 보다 값이 더 작게 나옴**

 이러한 **과소평가 되는 부분을 보완하기 위해 집단의 전체 개수(n)에서 1을 빼주어 전체 분산 값을 약간 키워줌**

 - 모분산은 n-1이 아닌 n으로 나눔

 **** n-1을 해주는 통계학적 이유**

 --> 데이터가 n개 있을 때, 그중 **n-1개의 데이터는 자유롭게 아무 값이나 가질수 있음**

 --> **마지막 1개의 데이터값은 편차의 합이 0이 되어야한다 라는 제약 조건때문에 값이 강제**로 결정됨

 --> 결과적으로 **실제로 독립적으로 정보를 제공하는 데이터의 개수는 n개가 아니라 n-1개라서 빼**주어야한다.

 **- 모분산 : 모집단 전체의 데이터가 모평균으로부터 얼마나 떨어져 있는지 나타내는 퍼짐 정도**

 --> 표본 분산과 달리 , **모집단은 전체 데이터를 다 알고 있으므로 N-1이 아닌 전체 개수 N으로 나눔**

![](https://blog.kakaocdn.net/dna/dcXJ5Q/dJMcaiPtndK/AAAAAAAAAAAAAAAAAAAAADFo1nVtcGq5Sfz3l3pfyt1OzrOnCDnQbb6KIDF3LXq0/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=343mLEVzGR5p2aGSVazrAHST1Ws%3D)

**(시그마 : 합계 , X : 모집단 데이터 값 , N : 모집단 전체 데이터 개수)**

 **- 표준편차 :**  **분산에 루트를 씌운 값**, 표준편차가 클수록 데이터가 넓게 퍼져 있다는 뜻

       * 실제로 사용하는 단위가 일치하기 떄문에 실무에서 자주 사용됨

![](https://blog.kakaocdn.net/dna/cVHMfH/dJMcai2Z0Of/AAAAAAAAAAAAAAAAAAAAAEKeZzTNSqFAfmWmCLRLrHnXjgf3DTukvvm7VS5Ns0H3/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=IGTF3GxWmYn3fwaFmfEvZ%2BVu8KA%3D)

**(시그마 : 합계 , x : 개별 데이터 값 , n : 데이터 개수)**

 **- 사분위수 : 데이터를 크기순으로 나열했을 때 4등분(25% , 50% , 75% , 100%)하는 지점들**

--> Q1 (제1사분위수) : 하위 25% 지점

--> Q2(제2사분위수) : 50% 지점 (중앙값)

--> Q3(제3사분위수) : 상위 25% 지점

--> **QR(사분위범위) : Q3 - Q1 값을 의미 , 데이터의 중간 50%가 얼마나 모여있는지 보여줌 , 이상치를 판별할때 핵심적인 기준이 됨**

## **상관관계 및 회귀분석**

#### **1. 정규 분포 (⭐️)**

 - **좌우가 대칭인 종 모양의 분포로 , 통계학에서 가장 중요한 분포**

 - 자연 현상이나 사회 현상의 많은 데이터가 이 정규분포를 따름

#### **2. 상관분석 (⭐️)**

 - 두 변수 사이에 어떤 선형적인 관계가 있는지 분석하는 것

#### **3. 상관관계 (⭐️)**

 - 두 변수가 함께 움직이는 경향성을 분석하는 단계 , 모집단 전체를 알 수 없기에 주로 표본을 통해 추측

#### **4. 상관계수 **(⭐️)****

 - 공분산을 각 변수의 표준편차로 나누어 -1에서 1사이의 값으로 표준화 시킴

 - 1에 가까우면 강한 양의 상관관계 (A가 커지면 B도 커짐)

 - -1에 가까우면 강한 음의 상관관계 (A가 커지면 B는 작아짐)

 - 0에 가까우면 관계 없음

![](https://blog.kakaocdn.net/dna/8zUO8/dJMb99LNJrw/AAAAAAAAAAAAAAAAAAAAAKs7dWEnI2ugVE_yrrdCrZexVURfHmuvsztiObJd-7mG/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=UO8iUVrdiaNrjntI4fyM2cqdeQ4%3D)

 - 단위의 영향을 받지 않음 r = 1 이면 완벽한 직선관계 , r = 0 이면 아무런 선형 관계가 없음을 뜻함

![](https://blog.kakaocdn.net/dna/p2ZCx/dJMcadN9nep/AAAAAAAAAAAAAAAAAAAAAI0FN96iSIgYY5c8HE_QP6srf5UugqvgJ43zbuvXk7YX/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=PIHNimVJQUbx0L0%2BkHtIIFv5k1E%3D)

**( Sxy : 공분산 , Sx , Sy : 각 변수의 표본표준편차 )**

#### **5. 공분산 **(⭐️)****

 - **두 변수 X , Y가 각자의 평균으로부터 떨어져 있는 정도(편차)를 서로 곱해서 합산한 값**

 - 양의 값 : X가 커질 때 Y도 커지는 경향

 - 음의 값 : X가 커질 때 Y는 작아지는 경향

![](https://blog.kakaocdn.net/dna/bB5jc9/dJMcafyufoP/AAAAAAAAAAAAAAAAAAAAAMKwprlaujnRUCPCM4INT6KA9FEhIWnhyLuD-MsoWISm/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=kCUUCvcnATSe4kqDOiKbhTTpmXE%3D)

수식 (표본 공분산)

 - **분산과 마찬가지로 표본에서는 n-1로 나눔** , 단점은 단위에 따라 값이 너무 커지거나 작아져서 강한 관계가 있는지 알기 어려움

#### **6. 회귀 분석 **(⭐️)****

 - 단순히 관계가 깊다(상관 관계)를 넘어 , 원인(X)과 결과(Y)의 관계를 수식으로 모델링하여 미래를 예측하는 기법

#### **7. 회귀계수 **(⭐️)****

 - **독립 변수 X가 1단위 변할 때 종속 변수 Y가 얼마나 변하는지를 나타내는 기울기**

 - **모회귀계수 (Beta) : 모집단 전체의 실제 기울기** (우리가 알고싶은 데이터)

 - **표본 회귀계수: 표본 데이터를 통해 계산해낸 기울기** (우리가 가진 최선의 추정치)

#### **8. 단순 선형 회귀식**

 - 하나의 X로 Y를 설명하는 가장 직선적인 모델

 **- 데이터들 사이를 가장 잘 가로지르는 최적의 직선을 찾는 것이 목표**

![](https://blog.kakaocdn.net/dna/bHzGim/dJMcahwi3jG/AAAAAAAAAAAAAAAAAAAAAHj34Ibk1DcQ-AN8lFW2yK2SiRbLEp9JW-TGX9iXy096/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=HlqGN4pOMuipbCTwhrceb0OdfO8%3D)

**( Y^: Y의 예측값 , b0 : Y 상수항 , b1 : 기울기 )**

#### **9. 잔차 , 오차 , 결정 계수**

 - 오차 (Error) : 모집단의 **실제 회귀식과 개별 데이터 사이의 차이**(현실적으로 알기 힘듦)

 - 잔차 (Residual) : **표본에서 구한 회귀식과 실제 관측값 사이의 차이**(우리가 실제로 계산하는 값)

     --> 회귀 분석은 이 잔차의 제곱합(SSE)을 최소로 만드는 직선을 찾는 과종 , 이를 최소제곱법이라고 부름

![](https://blog.kakaocdn.net/dna/vVwUU/dJMcahJQQ2M/AAAAAAAAAAAAAAAAAAAAAKRx1Es5bfXahUrzWmphT1HGW7sTrZymZ0UjMdK2xdzY/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=10cB6R9jYYyfb6L2GEhHvKZr8Z0%3D)

 - 결정계수 (R-Squared ,R^2) : **전체 데이터의 변동량 중에서 우리가 만든 회귀 모델이 설명해낼 수 있는 변동량의 비율**

     --> 0에서 1사이의 값을 가짐 , R^2 = 0.85라면 이 모델이 데이터 현상의 85%를 설명해준다 , 라고 해석할 수 있는 아주 중요한 지표

![](https://blog.kakaocdn.net/dna/bps6BG/dJMcabJDMUQ/AAAAAAAAAAAAAAAAAAAAAEjYw7kQMiSa0WKOQ-wawaK5za4FQuP-yEV6cY1-JSTr/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1769871599&allow_ip=&allow_referer=&signature=X2VD%2F%2FEABiqwzg1iOcGm0cV76D4%3D)