[[1.AI]]
## **글 쓴 이유**

 - 2026년이 되며 데이터 시장은 단순히 데이터를 분석하는 역할만 하는 데이터 분석가 , 데이터 베이스를 구축하고 성능을 효율적으로 관리하는 역할만 하는 데이터 엔지니어를 뽑지않음

 - 현재 AI 발전과 무수히 많은 자료의 공유로 인해 지식 습득과 접근성이 매우 좋아짐

 - 데이터 직군에 대한 미래의 역할 및 회사에서 원하는 데이터 직군의 능력을 정리해보겠음

  

  

## **데이터 직군 이해**﻿

 - 2026년 데이터 시장은 단순히 분석만 하거나 파이프라인만 구축하는 것을 넘어 , 각 직군의 경계가 허물어지며 새로운 역할이 중요해짐

 - AI 발전으로 인해 지식 접근성과 습득이 쉬워짐에 따라 이전 6~8년차 시니어들이 쌓아오던 지식과 기반을 AI 활용으로 3~4년 정도로 압축시킬수있음

 - AI 발전으로 데이터 직군의 인력 감소와 데이터 분석과 엔지니어링을 둘다 하는 능력자들을 찾거나 안뽑는 현상이 발생함

 - 분석 및 엔지니어링을 둘다 할수있는 능력을 가진 직군을 최근에는 Data Analytics Engineer(DAE) 라고 부름

  

### **Data Analytics Engineer ?**

 - 데이터 분석 엔지니어로써 데이터 엔지니어와 데이터 분석가 사이의 다리 역할을 하는 전문가 (둘 다 할 수 있는 전문가)

 - 과거에는 데이터 엔지니어가 데이터 인프라를 구축하고 , 분석가가 그 데이터를 활용했지만 , 현재는 인프라 구축과 분석을 둘 다 할수있어야함

  

#### **핵심 역할**

 - 데이터 모델링 : 데이터 창고에 들어온 파편화된 데이터를 분석이나 시각화 도구에서 바로 쓸 수 있도록 깨끗한 테이블로 모델링

 - 엔지니어링 전문성 도입 : 데이터 분석 업무에 소프르웨어 엔지니어링의 정수(버전 관리 , 데이터 테스트 ,문서화 ,CI/CD)를 도입해서 데이터의 신뢰성을 높임

 - 데이터 거버넌스 : 지표의 정의를 통일하여 부서마다 결과값이 다르게 나오는 혼란을 방지함

 - 정리하자면 **엔지니어가 수집한 로우 데이터를 분석가가 즉시 활용할 수 있도록 깨끗하고 잘 정리된 분석용 데이터 모델로 가공해야함**

 - 주요 툴 : dbt*(data build tool) , SQL , Data Warehouse(BigQuery,Snowflake)

  

## **2026년 데이터 분석가 핵심 목표 역량**

**데이터 분석가는 단순 시각화를 넘어선 비즈니스 임펙트와 AI 에이전트를 활용한 초고속 분석 능력이 필요함, 데이터 뒤에 숨겨진 맥락을 읽고 AI를 도구로 부릴 줄 아는 분석가를 목표로 해야함**﻿

####  **1. 분석 기본기**

 - 데이터를 읽고 다루는 근육 키우기

- **SQL**: 복잡한 비즈니스 로직을 쿼리로 구현 (다중 조인, 윈도우 함수, 성능 최적화)
- **Python (EDA)**: Pandas, Plotly를 활용한 데이터 탐색 및 인사이트 도출
- **통계학**: 가설 검정, 상관관계 분석, 회귀 분석 등 실무 통계 개념 이해

####  **2. 시각화 및 비즈니스 임팩트**

 - 숫자를 가치 있는 메시지로 바꿈

- **BI Tools**: Tableau, Superset 또는 Looker Studio 활용
- **Dashboard Design**: 사용자 목적에 맞는 UI/UX 설계 및 핵심 지표(KPI) 정의
- **Storytelling**: 분석 결과를 논리적인 비즈니스 언어로 전달하는 리포트 작성

####  **3. 프로덕트 및 그로스 분석**

 - 서비스의 성장을 데이터로 이끌어냄

- **지표 설계**: 리텐션, 퍼널(Funnel) 분석, LTV 분석
- **A/B Testing**: 실험 설계, 표본 크기 산정, 통계적 유의성 판단
- **이벤트 로그 설계**: 프로덕트 개선을 위한 유저 행동 로그 설계 및 관리

####  **4. AI 활용 분석**

 - 2026년 데이터 분석가의 핵심 차별화 포인트

- **AI Agentic EDA**: Antigravity, ChatGPT, Claude 등 AI 도구를 활용한 코드 생성 및 분석 자동화
- **프롬프트 엔지니어링**: 데이터 도메인에 특화된 프롬프트 작성 능력
- **LLM 인사이트 도출**: 비정형 데이터(리뷰, 채팅 로그)의 텍스트 마이닝 및 감성 분석 자동화 연동 파이프라인 이해

  

## **2026년 데이터 엔지니어 핵심 목표 역량**

**데이터 엔지니어에게 요구되는 역량도 단순 파이프라인 구축을 넘어 , AI 모델을 위한 데이터 처리와 인프라 관리로 확장되고 있음**﻿

####  **1. 기본기 다지기**

 - 언어 , CS 지식 , OS 환경지식이 가장 중요

- **언어**: Python (고급 문법, 비동기 처리, 타입 힌트), SQL (윈도우 함수, CTE, 쿼리 최적화)
- **컴퓨팅**: Linux/Shell Scripting, Git/GitHub 협업 흐름
- **CS 지식**: 자료구조/알고리즘, 네트워크 기초 (HTTP/API), 운영체제 기본

####  **2. 코어 데이터 엔지니어링**

 - 데이터를 저장하고 가공하는 핵심 능력

- **데이터 웨어하우스 & 모델링**:
    - Snowflake 또는 BigQuery 활용
    - 스타 스키마, 데이터 볼트(Data Vault) 모델링 이해
- **전통적 ETL vs Modern ELT**:
    - Pandas/Spark를 이용한 데이터 처리
    - **dbt (data build tool)**: SQL 기반의 데이터 변환 및 문서화 (필수 역량)

  

####  **3. 모던 데이터 스택 및 인프라**

 - 최신 트렌드에 맞는 도구들을 익힘

- **오케스트레이션**: Apache Airflow (또는 Dagster/Prefect)
    - 복잡한 의존성 관리 및 백필(Backfill) 전략
- **컨테이너 & 클라우드**:
    - Docker & Kubernetes (기본 개념 및 간단한 배포)
    - AWS 또는 GCP (IAM, S3/GCS, Lambda/Cloud Functions, VPC)
    - **IaC**: Terraform으로 인프라 코드로 관리하기

  

####  **4. 차별화 포인트**

 - 경쟁자들과 차별화 되는 포인트 무기를 습득해야함

- **AI/LLM 데이터 파이프라인**:
    - **RAG (검색 증강 생성)** 아키텍처 이해
    - **Vector Database** (Pinecone, Milvus 등) 구축 및 관리 경험
    - 비정형 데이터(텍스트, 이미지) 처리 파이프라인
- **데이터 품질 및 거버넌스**:
    - 데이터 계약 (Data Contracts) 개념 이해
    - 데이터 품질 테스트 (Great Expectations, Soda)
- **실시간 데이터 처리 (Streaming)**:
    - Kafka 또는 Redpanda 기본 아키텍처
    - Spark Streaming 또는 Flink 찍먹해보기